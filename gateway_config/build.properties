
# ####################################################################################
# If you are creating an application based on the cipres code, this file provides
# examples of properties you'll need to set in your application's build.properties file. 
# It also has default values for some properties.  Don't edit this file; instead
# override these values as needed by adding the properties to your build.properties file.
# ####################################################################################

# ####################################################################################
# tool-registry.cfg.xml properties 
# ####################################################################################

# tool.resource.cluster=<cluster>
# <cluster>.login=
# <cluster>.fileHost=
# <cluster>.submit=
# <cluster>.check=
# <cluster>.cancel=
# <cluster>.rc=
# <cluster>.project=
# <cluster>.workspace=

comet.cancel=comet_relion_cancel.py
comet.check=comet_relion_check.py
comet.fileHost=comet
comet.host=*
comet.keyFile=*
comet.login=*
comet.rc=*
comet.submit=comet_relion_submit.py
comet.username=*
comet.workspace=*

tool.resource.host=localhost

# ####################################################################################
# end tool-registry.cfg.xml properties 
# ####################################################################################


host=*

workspace=*

# teragrid.<host>.workspace=
# teragrid.<host>.host=
# teragrid.<host>.user=
# teragrid.<host>.login=
# teragrid.<host>.rc=
# teragrid.<host>.submit=
# teragrid.<host>.check=
# teragrid.<host>.cancel=
# <host>.filehandler=

# Set to "true" to disable teragrid tools, "false" to enable teragrid tools.  
teragrid.tools.disable=true

# teragrid.username=
# teragrid.password=
# triton.username=
# triton.keyFile=


# ####################################################################################
# GLOBUS  Teragrid Properties 
# ####################################################################################

# Units for the following are in minutes (1 hr=60, 1 day = 1440, 3 days = 4320, 7 days = 10080, etc)
# The longest proxy we can get from myproxy with our current credential is 7 days so
# there's no point trying to run jobs longer than that.  Lonestar only allows 2 days anyway.
grid.job.lifetime.max = 10080 

# Globus process worker polls very frequently the first minute, then at quick.poll.interval for 
# several minutes and finally at poll.interval.
grid.job.poll.interval = 60 
grid.job.medium.poll.interval = 5 
grid.job.quick.poll.interval = 1 

# Lifetime of credential in hours.  min.lifetime  must be less than lifetime.
# With the credential we're using (a default teragrid credential) 7 days = 168 hrs is the max
# we can get. 
grid.myproxy.lifetime = 168 
grid.myproxy.min.lifetime = 144 
grid.myproxyfile=/tmp/x509_portal

grid.globus.dir=@{env.HOME}/.globus

# ####################################################################################
# END GLOBUS  Teragrid Properties 
# ####################################################################################


# Used for sending job completion email and identifying which to process, "i.e. the 'submitter'".
portal.name=COSMIC2 Science Gateway
rest.name=REST Service
email.serviceAddr=*
email.adminAddr=*
job.email.from=COSMIC2 Science Gateway
job.email.enable=true
restSupportEmail=*

# In your build properties use settings like these:
mailSender=*
email.smtpServer=*
email.smtpServer.port=25

# or like these: 
# mailSender=gmail.mailSender
# mailSender.gmail.username=
# mailSender.gmail.password=
# email.smtpServer=smtp.gmail.com
# email.smtpServer.port=587



# maxPoolSize needs to be at least ( 2 * max(loadResults.pool.size, submitJob.pool.size) ) + 1
# to avoid deadlock.  Also make sure that in ssl.properties, maxconn for the hosts we're using
# is at least  2 * max(loadResults.pool.size, submitJob.pool.size) 
database.maxPoolSize=25
database.minPoolSize=2

ssl.maxconn=25

# Poll remote host for completed jobs every 5 minutes
checkJobs.poll.seconds=300
checkjobs.maxDays = 30

loadResults.poll.seconds=60
loadResults.pool.size=10
loadResults.retries=40

# Poll Globus transfer status every 5 minutes
checkGlobusTransfers.poll.seconds=300

# These are used in BaseProcessWorker.java resultsTooLarge(). They are long values.
# Results above these limits are not transferred back to the web app.
# Setting max sizes to 0 disables the limits and everything will be transferred.
max.file.size=0
max.dir.size=0

# Max size request, including a file upload, that struts/portal will accept.  Doesn't affect REST API.
# For the REST API, upload size limit is set by httpd apache mod_security.
portal.upload.size.limit=629145600

# Values used for user data storage size display (150 GB and 120 GB)
user.data.size.max=161061273600
user.data.size.warn=128849018880

submitJob.poll.seconds=10
submitJob.pool.size=10
submitJob.retries=3

disabled.resources.file=*
accounting.period.start=2016-07-01

# For the restapi user registration.  If user doesn't respond to email activation link in this many hrs, delete the account.
deleteUnactivatedUsers.hours=2

logs=*
portal.url=http://@{build.appServer.host}/@{build.portal.appName}
rest.callback.url=-k -K ~/.jobcurl.rc https://@{build.appServer.host}/@{build.rest.appName}/v1/admin/updateJob
portal.callback.url=-k https://@{build.appServer.host}:8443/@{build.portal.appName}/taskupdate.action
rest_url=https://@{build.appServer.host}/@{build.rest.appName}/v1
database.url=jdbc:log4jdbc:mysql://@{database.host}:@{database.port}/@{database.name}
database.driverClass=net.sf.log4jdbc.DriverSpy
database.fileRoot=*
database.globusRoot=*
database.useFileCompression=false
database.renameDuplicateLabels=true
database.host=*
database.port=*
database.name=*
database.username=*
database.password=*

tus.base=/v1/tmpfiles
tus.url=http://@{build.appServer.host}/@{build.rest.appName}@{tus.base}
tus.storage=@{database.fileRoot}/upload
default.import.folder=uploads
tus.enabled=true
fileapi.enabled=true

portal.enableIplant=0
python.install=develop

# For the rest api. These are user accounts and application names for tests and demos. 
testpass=*
pycipres_admin=pycipres_admin
pycipres_app=pycipres
pycipres2_app=pycipres2
pycipres_eu=pycipres_eu
pycipres_eu2=pycipres_eu2
guidemo_admin=guidemo_admin
guidemo_app=guidemo
guidemo2_admin=guidemo2_admin
guidemo2_app=guidemo2

# For the rest api, these are the limits in force.  Can override, in the db, for specific users and apps.
xsede_su_limit=30000 
other_su_limit=30000 
submitted_today_limit=50 
active_limit=50 
concurrent_limit=10
# no_limits=1

# For pycipres
# admin.username=
# admin.password=

build.appServer.host=*
build.piseXml.staticUrl=http://www.phylo.org
#build.portal.staticUrl=http://@{build.appServer.host}
build.portal.staticUrl=*
build.portal.trackerUrl=
build.portal.appName=gateway
build.portal.tomcatDir=@{env.CATALINA_HOME}
build.rest.appName=cipresrest
build.sdk.versionsDir=*
build.sdk.deployedScripts=daemonize, loadResultsD, recoverResultsD, checkJobsD, checkGlobusTransfersD, piseEval, userTgAllocation, userCanSubmit, userCountryIs, taskInspector, importTgusage, tgusage.sh, convertEncoding.sh, userDelete, sdkrun, submitJobD, updateLastLogin, mailer.py, cipresAdmin, db_password.txt, portal_allocation_message.txt, rest_allocation_message.txt, deleteUserData.py, deleteWarning1.txt, usage.py, usage.sh, update_crl.sh, deleteTasksD, usageLimits, deleteUnactivatedAccountsD



# ####################################################################################
# Filenames
# ####################################################################################
# job.system.files is a list of job working dir files that we don't want to store in the db
# and return to the user.  Filtered out by tool/OutputDescription.java.  The list excludes
# the files that Mark or user's find useful, namely:
#	_JOBINFO.TXT, scheduler.conf, _scheduler_stderr.txt
#	Mark says scheduler_stderr.txt is the only way user's know if a job timed out vs another error.  (I think we can use term.txt, but need to verify that).
#	Sherry He uses done.txt and term.txt.   Talk to Sherry about just using term.txt and when she converts to that we can stop returning done.txt.
#	Leaving start.txt for now so that we and the user knows if failed job even started running.
job.system.files=_COMMANDLINE, _batch_command.cmdline, _batch_command.run, _batch_command.status, _epilogue.sh, _scheduler_stdout.txt


# Set to false to disable GUEST login w/o registration
allowGuests=true
